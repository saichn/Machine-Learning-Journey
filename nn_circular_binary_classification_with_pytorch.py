"""
# Circle Classification Neural Network

This script implements a simple neural network using PyTorch to classify points in a 2D plane generated by the `make_circles` function from the `sklearn.datasets` module. The network is trained to distinguish between points in two concentric circles.

## Key Features:
- **Data Preparation**: Generates synthetic data with noise and splits it into training and testing sets.
- **Model Definition**: Defines a neural network with one hidden layer using sigmoid activation functions.
- **Training**: Trains the model using binary cross-entropy loss and the Adam optimizer.
- **Visualization**: Plots the decision boundary of the model before and after training, as well as the training loss over epochs.

## Usage:
Run the script to train the model and visualize the results.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from matplotlib.colors import ListedColormap

# Set random seed for reproducibility
seed = 7777
torch.manual_seed(seed)
np.random.seed(seed)

# Data Preparation
# Generate sample data with noise and factor parameters
X, y = datasets.make_circles(n_samples=1000, noise=0.1, factor=0.4, random_state=seed)

# Convert numpy arrays to PyTorch tensors
x_data = torch.Tensor(X)
y_data = torch.Tensor(y).view(-1, 1)

# Split data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=seed)

# Model Definition
class Model(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(Model, self).__init__()
        self.l1 = nn.Linear(input_size, hidden_size)
        self.l2 = nn.Linear(hidden_size, output_size)
        self.sigmoid = torch.sigmoid

    def forward(self, x):
        x = self.sigmoid(self.l1(x))
        x = self.sigmoid(self.l2(x))
        return x

    def predict(self, x):
        pred = self.forward(x)
        return np.where(pred.detach().numpy() >= 0.5, 1, 0)

# Helper function to plot training losses
def plot_losses(losses):
    plt.figure()
    plt.plot(losses)
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Epoch vs Training Loss')
    plt.grid()
    plt.show()

# Helper function to plot model fit
def plot_fit(model, X, y, plot_title):
    x_span = np.linspace(min(X[:, 0]), max(X[:, 0]), 50)
    y_span = np.linspace(min(X[:, 1]), max(X[:, 1]), 50)
    xx, yy = np.meshgrid(x_span, y_span)
    coordinates = np.c_[xx.ravel(), yy.ravel()]
    coordinates = torch.Tensor(coordinates)
    z = model(coordinates).detach().numpy().reshape(xx.shape)
    plt.contourf(xx, yy, z, cmap=ListedColormap(['white', 'black']), alpha=0.6)
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')
    plt.title(plot_title)
    plt.xlabel('X1')
    plt.ylabel('Y1')
    plt.show()

# Training
model = Model(input_size=2, hidden_size=4, output_size=1)
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.1)

# Initial model fit plot
plot_fit(model, x_train.numpy(), y_train.numpy(), 'Initial Fit')

# Training loop
epochs = 500
losses = []
for epoch in range(1, epochs + 1):
    y_pred = model(x_data)
    loss = criterion(y_pred, y_data)
    losses.append(loss.item())
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if epoch == 1 or epoch % 50 == 0:
        print(f"Epoch {epoch} loss: {loss.item()}")

# Final model fit plot
plot_fit(model, x_train.numpy(), y_train.numpy(), 'Final Fit')
plot_losses(losses)
plot_fit(model, x_test.numpy(), y_test.numpy(), 'Test Prediction')
